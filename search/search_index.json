{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Currently under development. File formats, command parameters, and functionality can (and most likely will) change.</p> <p>This is a copy program for SQL Server and Postgres.</p> <p>Eventually, it will be a copy tool for copying all schema and data from one database to another. It will also migrate schema and data between SQL Server and Postgres.</p> <p>Current, I have implemented functionality for migrating from SQL Server to Postgres:</p> <ul> <li>You can copy out from an SQL Server database, but not into one.</li> <li>You can copy into a Postgres database, but not out from one, and the schema and data files used, has to come from SQL Server</li> </ul> <p>The conversion of SQL Server data types to Postgres data types are \"static\". For more information about type conversions, go here.</p> <p>Indexes and foreign keys are handled, but not views, procedures, sequences, functions or collections.</p> <p>See Quick Start for more information about how collations are handled.</p>"},{"location":"command_line_parameters/","title":"Command line parameters","text":"<p>Listing the required ones first, then the optional ones in alphabetical order.</p>"},{"location":"command_line_parameters/#-c-connection-string-required","title":"-c, --connection-string (required)","text":"<p>The connection string. They can look something like this:</p>"},{"location":"command_line_parameters/#sql-server","title":"Sql Server","text":"<p>Server=.;Database=ABulkCopyTestDb;Trusted_Connection=True;MultipleActiveResultSets=true;</p> <p>Server=&lt;server name&gt;;Initial Catalog=&lt;database name&gt;;User Id=&lt;your user id&gt;;Password=&lt;your password&gt;;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;</p>"},{"location":"command_line_parameters/#postgres","title":"Postgres","text":"<p>Server=localhost;Port=5432;Database=ABulkCopyTestDb;User Id=postgres;Include Error Detail=True;</p> <p>Server=ah-postgres.postgres.database.azure.com;Port=5432;Database=&lt;database name&gt;;User Id=&lt;your user id&gt;;Include Error Detail=True;Password=&lt;your password&gt;;SSL Mode=Require;Trust Server Certificate=true;Command Timeout=1800;</p>"},{"location":"command_line_parameters/#-d-direction-required","title":"-d, --direction (required)","text":"Legal values In Out <p>Which way you are copying data. \"In\" to a database or \"Out\" from a database</p>"},{"location":"command_line_parameters/#-r-rdbms-required","title":"-r, --rdbms (required)","text":"Legal values Pg Mss <p>What Relational Database Management System (RDBMS) you are using.</p>"},{"location":"command_line_parameters/#-q-add-quotes-in-only","title":"-q, --add-quotes (In only)","text":"<p>Flag to quote all identifiers. Only applicable for Postgres, where there is a significant difference in behaviour when quoting identifiers.</p> <p>Warning</p> <p>When a table/column name is quoted in Postgres, you must ALWAYS use quotes when referring to this name in queries and statements. Otherwise, Postgres will throw an error, saying that it can't find the object.</p> <p>Note</p> <p>Postgres reserved words are always quoted.</p> <p>Note</p> <p>For SQL Server, identifiers will always be quoted (this parameter is ignored).</p>"},{"location":"command_line_parameters/#-empty-string-in-only","title":"--empty-string (In only)","text":"<p>Describe how to handle empty strings, or strings that contains whitespace only.</p> <p>Legal values:</p> Value Description Single An empty string is converted to a single space Empty A single space is converted to an empty string ForceSingle If the string is empty or contains only whitespace, it's converted to a single space ForceEmpty If the string contains only whitespace, it's converted to an empty string"},{"location":"command_line_parameters/#-f-folder-both-directions","title":"-f, --folder (both directions)","text":"<p>The source/destination folder for schema and data files.</p>"},{"location":"command_line_parameters/#-help","title":"--help","text":"<p>Display a short description of all the command line parameters.</p>"},{"location":"command_line_parameters/#-l-log-file-both-direction","title":"-l, --log-file (both direction)","text":"<p>Full path for the log file</p> <p>Note</p> <p>The log files contains A LOT of details, and can be quite huge. The probram will also append to a log file, if it already exists. I reccommend deleting the log file before every run.</p>"},{"location":"command_line_parameters/#-m-mappings-file-in-only","title":"-m, --mappings-file (In only)","text":"<p>The path and file name of a json file containing key-value pairs for mapping schema names and collation names. E.g. mapping the \"dbo\" schema in SQL Server to the \"public\" schema in Postgres. There is a sample-mappings.json file accompanying the executable. It looks like this:</p> <pre><code>{\n  \"Schemas\": {\n    \"\": \"public\",\n    \"dbo\": \"public\"\n  },\n  \"Collations\": {\n    \"SQL_Latin1_General_CP1_CI_AI\": \"en_ci_ai\",\n    \"SQL_Latin1_General_CP1_CI_AS\": \"en_ci_as\"\n  },\n  \"ColumnTypes\": {\n    \"binary\": \"bytea\",\n    \"bit\": \"boolean\",\n    \"datetime\": \"timestamp with time zone\",\n    \"datetime2\": \"timestamp with time zone\",\n    \"datetimeoffset\": \"timestamp with time zone\",\n    \"float\": \"doubleprecision\",\n    \"nchar\": \"char\",\n    \"text\": \"varchar\",\n    \"ntext\": \"varchar\",\n    \"nvarchar\": \"varchar\",\n    \"smalldatetime\": \"timestamp with time zone\",\n    \"tinyint\": \"smallint\",\n    \"uniqueidentifier\": \"uuid \",\n    \"image\": \"bytea\",\n    \"varbinary\": \"bytea\"\n  }\n}\n</code></pre> <p>Warning</p> <p>Currently, you should only add/change mappings for Schemas and Collations, and for the bit and datetime types.</p> <p>The ColumnTypes mapping is currently very simple, and will be changed in the future. For now, you should only change bit and the datetime types, and only use the values:</p> bit datetime, datetime2, datetimeoffset boolean timestamp with time zone smallint timestamp int"},{"location":"command_line_parameters/#-schema-filter-out-only","title":"--schema-filter (Out only)","text":"<p>A comma separated list of schema names.</p> <p>Note</p> <p>When it's not used, all schemas will be copied, except 'guest', 'information_schema', 'sys' and 'logs'.</p>"},{"location":"command_line_parameters/#-s-search-filter-both-directions","title":"-s, --search-filter (both directions)","text":"<p>A string to filter table names or file names. Note that the syntax of the SearchFilter is different depending on the direction parameter.</p>"},{"location":"command_line_parameters/#when-copying-out","title":"When copying out","text":"<p>For copy out, the SearchFilter is the rhs of a LIKE clause in SQL.</p> Sample string Description a[^_]% Get all tables except the ones starting with underscore a[sa][ya][sg]% Get all tables that starts with 'a' followed by \"sys\" or \"aag (but will also get \"asas\", \"aayg\", and other combinations)"},{"location":"command_line_parameters/#when-copying-in","title":"When copying in","text":"<p>For copy in from a file system, use a RegEx in .NET format.</p> Sample string Description (client|scope) Match all tables containing the words client or scope \\b(clients|scopes)\\b will match clients.schema and scopes.schema, but not someclients.schema nor clients2.schema"},{"location":"command_line_parameters/#-skip-create-in-only","title":"--skip-create (In only)","text":"<p>It assumes that the tables already exists in the database, and will skip the \"create table\" step. The thought is that tables are created using Entity Framework migrations, then ABulkCopy is used to insert data.</p> <p>Warning</p> <p>Schema files are still needed to create the dependency graph and the copy statements, and they MUST correspond to the tables already in the database.</p>"},{"location":"command_line_parameters/#-to-lower-in-only","title":"--to-lower (In only)","text":"<p>When importing tables, all identifiers (table names, column names, etc.) will be converted to lowercase.</p> <p>Note</p> <p>Postgres will always fold all names to lowercase, unless they are quoted. So for Postgres, this has no effect unless you also use it with the --add-quotes parameter</p>"},{"location":"command_line_parameters/#-version","title":"--version","text":"<p>Show the version of the binary files</p> <p>Note</p> <p>This version is not the same as the Release version you find under Releases in GitHub.</p>"},{"location":"quick_start/","title":"Quick Start","text":"<p>To get started, get the latest release from https://github.com/ArveH/ABulkCopy.</p> <p>You find there Releases on the right-hand side panel:</p> <p></p> <ol> <li>Open the Latest release by clicking on it.</li> <li>Download the \"Release-vx.y.z.zip\" file</li> <li>Unzip the file, and run: <code>.\\ABulkCopy.Cmd.exe --help</code></li> </ol> <p>To move data from SQL Server to Postgres, you run it twice. First, you copy tables out from SQL Server into files. Then you use the same files to create tables and copy data into Postgres. Here is an example showing the command line parameters you need to use:</p> Copy outCopy in <pre><code>.\\ABulkCopy.Cmd.exe -d out -r Mss\n-c \"Server=.;Database=mydb;Trusted_Connection=True;TrustServerCertificate=True;MultipleActiveResultSets=true\"\n-l D:\\Temp\\abulkcopy\\Logs\\out.log\n-f d:\\temp\\abulkcopy\\LocalDbs\\mydb\n</code></pre> <pre><code>.\\ABulkCopy.Cmd.exe -d in -r Pg\n-c \"Server=localhost;Port=5432;Database=mydb;User Id=postgres;Include Error Detail=True;Command Timeout=1800;\"\n-l D:\\Temp\\abulkcopy\\Logs\\in.log\n-f D:\\temp\\abulkcopy\\LocalDbs\\mydb\n</code></pre> <p>Remember that the Postgres database you copy into should be existing, empty, and containing these collations:  </p> <pre><code>DROP COLLATION IF EXISTS en_ci_ai;\nCREATE COLLATION en_ci_ai (provider = 'icu', locale = 'en-u-ks-level1', deterministic = false);\n\nDROP COLLATION IF EXISTS en_ci_ai_like;\nCREATE COLLATION en_ci_ai_like (provider = 'icu',  locale = 'en-u-ks-level1',  deterministic = true);\n\nDROP COLLATION IF EXISTS en_ci_as;\nCREATE COLLATION en_ci_as (provider = 'icu', locale = 'en-u-ks-level2', deterministic = false);\n\nDROP COLLATION IF EXISTS en_ci_as_like;\nCREATE COLLATION en_ci_as_like (provider = 'icu',  locale = 'en-u-ks-level2',  deterministic = true);\n</code></pre> <p>The collations are needed to convert the SQL Server collations SQL_Latin1_General_CP1_CI_AI and SQL_Latin1_General_CP1_CI_AS to equivalent Postgres collations (to handle case insensitivity). Later, you will be able to customize this.</p>"},{"location":"release_notes/","title":"Release Notes","text":"<p>Before I get more functionality implemented, the Major version number will not be used.</p> <p>The Minor version number will change where there is significant new functionality, otherwise it's only the Patch number that will change.</p>"},{"location":"release_notes/#087-added-pre-script-and-post-script-parameters","title":"0.8.7 Added --pre-script and --post-script parameters","text":"<p>You can create simple script files that can be run before and after data is copied. I use it to create collations before I start copying into Postgres, and to update the __EFMigrationsHistory table after the copy has finished.</p>"},{"location":"release_notes/#086-handle-x00-in-strings","title":"0.8.6 Handle \\x00 in strings","text":"<p>PostgreSQL does not allow null bytes (\\x00) in text (TEXT, VARCHAR) columns because it uses C-style strings internally, which treat \\x00 as a string terminator. Sql Server do allow this, so when copying data that had zero bytes inside the string, it crashed. It will now remove these zero-bytes when copying.</p>"},{"location":"release_notes/#085-build-linux-x64","title":"0.8.5 Build Linux-x64","text":"<p>No functionality is changed. I just added a binary for linux-x64. So now we have binaries for windows-x64, mac-arm64, linux-x64 and linux-arm64</p>"},{"location":"release_notes/#084-builds-for-windows-linux-and-mac","title":"0.8.4 Builds for Windows, Linux and Mac","text":"<p>No functionality is changed. If you have version 0.8.2 and running on Windows, you don't have to upgrade. This release only adds builds for Linux and Mac.</p>"},{"location":"release_notes/#083-updated-workflow-file","title":"0.8.3 Updated workflow file","text":"<p>Only the workflow file was updated, so there is no change to the program. The workflow file was using two depricated actions for creating a release. These where replaced.</p>"},{"location":"release_notes/#082-dont-prompt-when-folder-doesnt-exist","title":"0.8.2 Don't prompt when folder doesn't exist","text":"<p>Just a small change. Decided to remove the prompt for when folder doesn't exist. It doesn't really make sense to prompt here. I've created a new issue for halting if files are overwritten instead (Issue 41).</p>"},{"location":"release_notes/#081-breaking-change-changed-bool-and-datetime-default-mappings","title":"0.8.1 Breaking change: Changed bool and datetime default mappings","text":"<p>When converting from SqlServer to Postgres, bit is now translated to boolean (previously smallint) and datetime/datetime2 is translated to timestamp with time zone (previously timestamp without time zone). However, you can change to the old mappings by using the --mappings-file parameter. See the Documentation.</p> <p>The data files are changed. All DateTime's are noe stored as UTC, and marked as such by ending the datetime string with a Z, e.g. 2024-06-26 11:00:00Z</p>"},{"location":"release_notes/#070-added-command-line-parameter-to-lower","title":"0.7.0 Added command line parameter --to-lower","text":"<p>This parameter will convert all identifiers (table names, column names, etc.) to lowercase. NOTE: For Postgres, this parameter will have no effect unless it's used in conjunction with the --add-quotes parameter, since Postgres will \"fold\" the identifier names to lowercase if they are not quoted. The --to-lower parameter is only used when direction = In</p>"},{"location":"release_notes/#060-added-command-line-parameter-skip-create","title":"0.6.0 Added command line parameter --skip-create","text":"<p>Added a flag that can be used to skip creating tables and indexes, and only insert data. It's an experimental feature that might be removed or changed in the future.</p>"},{"location":"release_notes/#050-major-change-internal-functionality-rewritten-to-handle-schemas","title":"0.5.0 Major change. Internal functionality rewritten to handle schemas","text":"<p>All lookup in system tables had to be changed to handle schemas. The schema and data files are also changed. The file names are prefixed with the schema they belong to. The .schema file now store information about the schema.</p> <p>Two new command line parameters where added. One for filtering on schemas (--schema-filter), and another for giving a file path for a file describing what a schema in SQL Server should be mapped to in Postgres (-m or --mapping-file). A sample-mappings.json file now accompanies the executable.</p>"},{"location":"release_notes/#042-fixed-error-reset-auto-generation-for","title":"0.4.2 Fixed: **ERROR** Reset auto generation for ...","text":"<p>When the length of the name of the table, and the length of the name of the identity column, together was getting close to 64 characters long, the copy program crashed when trying to copy into Postgres. This is now fixed.</p>"},{"location":"release_notes/#021-character-lengths","title":"0.2.1 Character lengths","text":"<p>When getting the information from SQL Server's system tables, I used the length in bytes as output to the schema files. For string types, it makes more sense to use the character length. For example, it caused nvarchar columns copy from SQL Server to Postgres to become twice as long in Postgres. This is now fixed. I also fixed some other small errors with length, scale and precision for other types.</p>"},{"location":"release_notes/#020-initial-release","title":"0.2.0 Initial Release","text":"<p>This is the initial release. It is currently only usable for migrating from SQL Server to Postgres:</p> <ul> <li>You can copy out from an SQL Server database, but not into one.</li> <li>You can copy into a Postgres database, but not out from one, and the schema and data files used, has to come from SQL Server</li> </ul> <p>The conversion of SQL Server data types to Postgres data types are \"static\". For more information about type conversions, go here.</p> <p>Indexes and foreign keys are handled, but not views, procedures, sequences, functions or collections.</p> <p>See Quick Start for more information about how collations are handled. </p>"},{"location":"type_mss_pg/","title":"Type Conversion from SQL Server to Postgres","text":"<p>If the type is not listed in this table, it is assumed that the same type exists in Postgres. If it doesn't, the import will probably fail. Eventually, this will be configurable.</p> SQL Server Postgres Binary ByteA Bit Boolean DateTime TimestampTz DateTime2 TimestampTz DateTimeOffset TimestampTz Float DoublePrecision NChar Char Text Varchar NText Varchar NVarchar Varchar SmallDataTime Timestamp TinyInt SmallInt UniqueIdentifier Uuid Image ByteA VarBinary ByteA"}]}